<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>OISST_with_gmRi.utf8.md</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">


background-image: url(GMRI_template_slide1.png)
background-size: cover
class: center middle inverse


# OISST Temperature Products
## Accessed with the {gmRi} package
#### By: Adam Kemberling
#### Gulf of Maine Research Institute
Updated: 2020-11-30







---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

.center[
# The gmRi Package for R-Users
]

## Vision:   
Create shared tools for accessing commonly shared resources within gmRi

## Current / Future Functionality
 * GMRI Color Palette and Design Styles   
 * Shared Resource Access Functions   
 * Shared code for processing pipelines (Groundfish Prep?)




---
background-image: url(GMRI_template_slide_white.png)
background-size: cover


# Installing the `gmRi` Package

Install the **{gmRi}** package from [Github](https://github.com/gulfofmaine/gmRi):


```r
devtools::install_github("https://github.com/gulfofmaine/gmRi")
```


Once the package is loaded gmri color palettes can be accessed directly in this way:



```r
library(gmRi)
ggplot(mpg, aes(manufacturer, fill = manufacturer)) +
   geom_bar() +
   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
   scale_fill_gmri(palette = "mixed", guide = "none")
```

&lt;img src="OISST_with_gmRi_files/figure-html/unnamed-chunk-2-1.png" style="display: block; margin: auto;" /&gt;


---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# gmRi Package Vignettes

Currently there are two vignettes on [github](https://github.com/gulfofmaine/gmRi/blob/master/index.md):

 * [Accessing GMRI Style Elements](https://gulfofmaine.github.io/gmRi/doc/GMRI_Style_Doc.html) - For information on how to access the different GMRI color palettes as well as css stylesheets and html headers/footers for customizing Rmarkdown and Shiny output.   
&lt;br/&gt;
 * [OISST How-To](https://gulfofmaine.github.io/gmRi/doc/oisst_howto.html) - Functions relating to the download of OISST data directly from THREDDS in addition to helper functions for processing the data found on box.


---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# OISST Temperature Data Access

For the purposes of this presentation the focus will be on the [Optimum Interpolated Sea Surface Temperature Dataset OISST v2](https://www.ncdc.noaa.gov/oisst/optimum-interpolation-sea-surface-temperature-oisst-v21)

This dataset contains daily temperature readings at a resolution of 1/4 degrees lat/lon from the fall of 1981 through the present.

For many of our common use cases the global observations have been pre-processed and stored on box as part of the NSF Convergence Project, though they also exist in different forms across other folders on Box.

The goal is to remove those redundancies.

---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# NSF Convergence Accelerator Project

A main part of the convergence project was the creation of a knowledge graph. 

The knowleddge graph contained information about various datasets and their analysis code, and linked workflows and resources together that shared common components.

Part of process for populating the knowledge graph was detailing the many different commonly used permutations of the OISST data set. For those purposes, those resources were pre-processed and placed onto `Box`


---
background-imag: url(GMRI_template_slide_white.png)
background-size:cover


# Keeping What Worked

Although the knowledge graph itself may not be necessary, processing code and data in the knowledge graph had useful application for other projects.

OISST-specific python notebooks and R processing scripts were moved to a dedicated repository on box: [OISST Mainstays](https://github.com/adamkemberling/oisst_mainstays)


---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# OISST Resources From OKN

 - Daily Sea Surface Temperature Netcdfs
 - 1982-2011 Climatology
 - Daily Temperature Anomalies
 - Regional Temperature and Anomaly Timeseries
 - Pixel-by-pixel Warming Rates


---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

#Global Extent Files

Pre-downloaded and processed global arrays include:   
 * Global extent `.nc` files for daily temperatures
 * Global extent `.nc` file for 1982-2011 Climatology
 * Global extent `.nc` file for temperature anomalies
 * Global extent `.nc` file of pixel-by-pixel warming rates and their ranks

These are the foundational processing steps for any other temperature product and are done in python. These steps can each be found [here](https://github.com/adamkemberling/oisst_mainstays/tree/master/notebooks) and are prefixed with `BASE`.

---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# Loading Specific Window using {gmRi}


In many cases you only need a specific area of interest, and loading the full extent for every year brings too much into memory for R.

The `oisst_window_load` function exists to subset each year of the OISST data on box using a window of your choice, stepping through each year individually:


```r
# Connect to nsf convergence data path
okn_path &lt;- shared.path(group = "NSF OKN", folder = "")

# specify lat/lon/time window
data_window &lt;- data.frame(
  lon = c(-72, -65), 
  lat = c(42,   44), 
  time = as.Date(c("2019-08-01", "2020-12-31")))

# Load what we need, not what we don't
oisst_stack &lt;- oisst_window_load(okn_path = okn_path, 
                                 data_window = data_window)
```



---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# Loading Specific Window using {gmRi} pt. 2

Dates can then be plotted again just like before. Additional development to choose raw data or anomalies is under way, but right now it only returns raw data.


```r
# Grab a Date
aug2 &lt;- oisst_stack$`2019`$X2019.08.02

# Make stars object as ggplot2 snob
aug2_st &lt;- st_as_stars(aug2)

# Build Plot
august_plot &lt;- ggplot() +
  geom_stars(data = aug2_st) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", na.value = "gray20") +
  map_theme +
  coord_sf(expand = FALSE) +
  guides("fill" = guide_colorbar(title = "OISST - August 2nd - 2019",
                                 title.position = "top", title.hjust = 0.5,
                                 barwidth = unit(4, "in"), frame.colour = "black", 
                                 ticks.colour = "black"))
```

---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# Loading Specific Window using {gmRi} pt. 3

For these plots the stack is still aware of the data range for the entire extent so getting the color scale right will require some tuning. 


```r
# Plot
august_plot + ggtitle("Gulf of Maine OISST - Accessed via data window")
```

&lt;img src="OISST_with_gmRi_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;


---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# Global Netcdf Access

The global extent files are stored on box within the `NSF OKN Demo Data/oisst` folder. There is a netcdf file for each year for both the annual observations and the anomalies.

Using the `gmRi::shared.path()` function we can orient to the folder with anomaly files and pull the 2020 file this way:


```r
# Access information to netcdf on box
okn_path  &lt;- shared.path(group = "NSF OKN", folder = "oisst/annual_anomalies/")
nc_year   &lt;- "2020"
nc_path &lt;- str_c(okn_path, "daily_anoms_", nc_year, ".nc")

# Load 2020 with raster::stack()
anoms_2020 &lt;- raster::stack(nc_path)

# Use stack names to access layers for July
# Get the mean temperature anomalies for July
july_dates &lt;- which(str_sub(names(anoms_2020), 7, 8) == "07")
july_avg   &lt;- mean(anoms_2020[[july_dates]])

# Convert wgs84 to stars object to plot raster with ggplot
july_st &lt;- st_as_stars(rotate(july_avg))
```



---


# Mapping Raster with ggplot2




.pull-left[

```r
# Plot
anomaly_plot &lt;- ggplot() +
  geom_stars(data = july_st) +
  scale_fill_gradient2(
    low = "blue",
    mid = "white",
    high = "red",
    na.value = "gray20") +
  map_theme +
  coord_sf(expand = FALSE) +
  guides(
    "fill" = guide_colorbar(
      title = "Average Sea Surface Temperature Anomaly",
      title.position = "top", 
      title.hjust = 0.5,
      barwidth = unit(4, "in"), 
      frame.colour = "black", 
      ticks.colour = "black"))
```
]



.pull-right[
![](OISST_with_gmRi_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;
]


---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# Regional Timelines

For areas that GMRI commonly works with (ex. Gulf of Maine, Georges Bank, Northeastern US Shelf) these areas have pre-processed timelines.

The jupyter notebook code for their processing can be found [here](https://github.com/adamkemberling/oisst_mainstays/blob/master/notebooks/03_BASE_NMFS_region_timeseries.ipynb)

These tables each contain:   
 * Daily SST
 * Day of Year Climate Mean (within regional area)
 * Daily SST Anomalies
 * Standard deviation of SST Anomalies
 * Log-Likelihood of Observed Anomaly Given ~N(climate mean, climate sd)



---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# Regional Timeline Access

Code to process timelines has been run for the following regions:
 * Large Marine Ecosystems
 * Gulf of Maine 
 * NMFS Trawl Survey Regions
 
Files are stored in sub-folders based on the group that they are processed in. For example, the NMFS regions are stored in `Box/NSF OKN Demo Data/oisst/likelihood_timeseries/nmfs_trawl_regions`



---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# Regional Timeline Tables


```r
# Path to trawl region timeseries
trawl_region_path &lt;- shared.path(
  group = "NSF OKN", 
  folder = "oisst/likelihood_timeseries/nmfs_trawl_regions/")
table_name &lt;- "OISSTv2_anom_gulf_of_maine_likelihood_ts.csv"
gom_path &lt;- str_c(trawl_region_path, "/", table_name)

# Load and display
gom_ts &lt;- read_csv(gom_path, guess_max = 1e4, col_types = cols())
head(gom_ts, 3) %&gt;% select(time, sst, sst_clim, sst_anom, log_lik) %&gt;%  kable(format = "html")
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; time &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; sst &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; sst_clim &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; sst_anom &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; log_lik &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1981-09-01 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15.56767 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 16.44248 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.8748112 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.587300 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1981-09-02 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15.63219 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 16.29203 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.6598396 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.551383 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1981-09-03 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15.43664 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 16.24344 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.8067951 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.581632 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;




---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# OISST_Mainstays Organization


## **BASE** Notebooks

These notebooks are the foundational notebooks that create the global extent netcdf files that are re-purposed to return the regional products. The *BASE* notebooks take a **LONG** time to run, but only need to be run once, or in the event that we wish to change the reference period.

## **UPDATE** Notebooks

The UPDATE notebooks are designed to append new data onto the products of the *BASE* notebooks. Currently the workflow is to manually download a more recent netcdf of the OISST data. The notebooks then compare those observations to the climatology we have and append the anomalies as needed. These are much faster to run and could ideally be set up with continuous integration or with scheduled jobs.



---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# OISST_Mainstays Update Cycle

### 1. Establish Base Resources

Run *BASE* notebooks. This step is time consuming but does not need to be repeated.


### 2. Update **NSF OKN Demo Data/oisst** Resources

 1. Download most recent data
 2. Run *Update* Notebooks to append new data
 
 
### 3. Update Reports (ex. Gulf of Maine Warming)

Following the updates to oisst data resources, simply knit the rmarkdown file to reflect more current data.









---
background-image: url(GMRI_template_slide_white.png)
background-size: cover

# Future OISST Development Needs

**Consensus on naming structures:**    
Naming conventions and folder structures were done in a "by the seat of your pants" way. Names are cumbersomely long as a consequence. As part of producing this the "masked_timeseries" folder was shown to be completely redundant.


**Consensus on Shapefiles**    
In making the [Gulf of Maine Report](https://adamkemberling.github.io/oisst_mainstays/R/GOM_Report.html) I came across 5 different Gulf of Maine shapefiles in use for various projects. 


**Developing Continuous Integration**    
Currently updates are run in sequence manually. If the data download can be scheduled we should be able to schedule running the notebooks as well to provide a consistent update scchedule.


**{gmRi} Functions**   
Discussion on preferences for accessing and displaying data. Should we use THREDDS anymore? If not, much of the original vignette is not helpful.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"seal": false,
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
